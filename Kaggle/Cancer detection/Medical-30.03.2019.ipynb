{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f58d9dc12fae65dfae0d415a92b9b99b3c78cb94"
   },
   "source": [
    "## Medical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "6702c34bd58b243538a43f91d8874d641969fe15"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 6556657694481780977\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 4945621811\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 15680467377423217328\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:08:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from math import *\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "from scipy import stats\n",
    "import cv2\n",
    "import keras\n",
    "from keras.models import Sequential, model_from_yaml, Model\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Activation, Convolution2D, Flatten, \\\n",
    "    MaxPooling2D,Input, Concatenate, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras import backend as K\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow.python.ops import array_ops\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import *\n",
    "from keras.applications.densenet import DenseNet169\n",
    "from keras_applications.resnext import ResNeXt50\n",
    "import albumentations\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(device_lib.list_local_devices())\n",
    "config = tf.ConfigProto(device_count={\"CPU\": 1, \"GPU\" : 1})\n",
    "session = tf.Session(config=config)\n",
    "K.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_transform = albumentations.Compose([\n",
    "    albumentations.RandomRotate90(p=0.5),\n",
    "    albumentations.Transpose(p=0.5),\n",
    "    albumentations.Flip(p=0.5),\n",
    "    albumentations.OneOf([albumentations.CLAHE(clip_limit=2), \n",
    "                         albumentations.IAASharpen(), \n",
    "                         albumentations.IAAEmboss(), \n",
    "        albumentations.RandomBrightness(), \n",
    "                         albumentations.RandomContrast(),\n",
    "        albumentations.Blur(), \n",
    "                          albumentations.GaussNoise(),\n",
    "                          albumentations.ElasticTransform(),\n",
    "                         ], p=0.25), \n",
    "        albumentations.HueSaturationValue(p=0.25), \n",
    "        albumentations.ShiftScaleRotate(shift_limit=0.10, scale_limit=0.10, rotate_limit=0, p=0.5),\n",
    "        albumentations.Normalize(p=1)\n",
    "    \n",
    "    ])\n",
    "\n",
    "val_transform = albumentations.Compose([\n",
    "    albumentations.Normalize(p=1)\n",
    "    ])\n",
    "\n",
    "test_transform = albumentations.Compose([\n",
    "    albumentations.RandomRotate90(p=0.5),\n",
    "    albumentations.Flip(p=0.5),\n",
    "    albumentations.Normalize(p=1)\n",
    "    ])\n",
    "\n",
    "def preprocess_train(image):\n",
    "    return (train_transform(image = image.astype(np.uint8))['image'])\n",
    "\n",
    "def preprocess_val(image):\n",
    "    return (val_transform(image = image.astype(np.uint8))['image'])\n",
    "    \n",
    "def preprocess_test(image):\n",
    "    return (test_transform(image = image.astype(np.uint8))['image'])\n",
    "\n",
    "def preprocess_np(image):\n",
    "    return (image.astype(np.uint8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NPGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, batch_size=32, indep=np.empty([0,96,96,3]), dep = np.empty([0]), transform = preprocess_train):\n",
    "        'Initialization'\n",
    "        self.batch_size = batch_size\n",
    "        self.indep = indep\n",
    "        self.dep = dep\n",
    "        self.index = 0\n",
    "        self.transform = transform\n",
    "        self.tr = (lambda x: transform(image=x))\n",
    "        \n",
    "    def __len__(self):\n",
    "        l = int(np.floor(len(self.indep) / self.batch_size))\n",
    "        if ((len(self.indep) % self.batch_size) >0):\n",
    "            l+=1\n",
    "        return l\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X, y = self.indep[self.index * self.batch_size:(self.index + 1) * self.batch_size], \\\n",
    "               self.dep[self.index * self.batch_size:(self.index + 1) * self.batch_size]\n",
    "            \n",
    "        X = np.array([self.tr(img.astype(np.uint8)).reshape(96,96,3) for img in X])   \n",
    "        \n",
    "        self.index +=1\n",
    "        if (self.index>=self.indep.shape[0]/self.batch_size):\n",
    "            self.index=0    \n",
    "        return X, y\n",
    "\n",
    "    def reset(self):\n",
    "        self.index=0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import *\n",
    "\n",
    "class CyclicLR(Callback):\n",
    " \n",
    "    def __init__(self, base_lr=0.001, max_lr=0.006, step_size=2000., mode='triangular',\n",
    "                 gamma=1., scale_fn=None, scale_mode='cycle'):\n",
    "        super(CyclicLR, self).__init__()\n",
    "\n",
    "        self.base_lr = base_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.step_size = step_size\n",
    "        self.mode = mode\n",
    "        self.gamma = gamma\n",
    "        if scale_fn == None:\n",
    "            if self.mode == 'triangular':\n",
    "                self.scale_fn = lambda x: 1.\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'triangular2':\n",
    "                self.scale_fn = lambda x: 1/(2.**(x-1))\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'exp_range':\n",
    "                self.scale_fn = lambda x: gamma**(x)\n",
    "                self.scale_mode = 'iterations'\n",
    "        else:\n",
    "            self.scale_fn = scale_fn\n",
    "            self.scale_mode = scale_mode\n",
    "        self.clr_iterations = 0.\n",
    "        self.trn_iterations = 0.\n",
    "        self.history = {}\n",
    "\n",
    "        self._reset()\n",
    "\n",
    "    def _reset(self, new_base_lr=None, new_max_lr=None,\n",
    "               new_step_size=None):\n",
    "        if new_base_lr != None:\n",
    "            self.base_lr = new_base_lr\n",
    "        if new_max_lr != None:\n",
    "            self.max_lr = new_max_lr\n",
    "        if new_step_size != None:\n",
    "            self.step_size = new_step_size\n",
    "        self.clr_iterations = 0.\n",
    "        \n",
    "    def clr(self):\n",
    "        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n",
    "        x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n",
    "        if self.scale_mode == 'cycle':\n",
    "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(cycle)\n",
    "        else:\n",
    "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(self.clr_iterations)\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        logs = logs or {}\n",
    "\n",
    "        if self.clr_iterations == 0:\n",
    "            K.set_value(self.model.optimizer.lr, self.base_lr)\n",
    "        else:\n",
    "            K.set_value(self.model.optimizer.lr, self.clr())        \n",
    "            \n",
    "    def on_batch_end(self, epoch, logs=None):\n",
    "        \n",
    "        logs = logs or {}\n",
    "        self.trn_iterations += 1\n",
    "        self.clr_iterations += 1\n",
    "\n",
    "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
    "        self.history.setdefault('iterations', []).append(self.trn_iterations)\n",
    "\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "        \n",
    "        K.set_value(self.model.optimizer.lr, self.clr())\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def KerasFocalLoss(target, input):\n",
    "    \n",
    "    gamma = 2.\n",
    "    input = tf.cast(input, tf.float32)\n",
    "    \n",
    "    max_val = K.clip(-input, 0, 1)\n",
    "    loss = input - input * target + max_val + K.log(K.exp(-max_val) + K.exp(-input - max_val))\n",
    "    invprobs = tf.log_sigmoid(-input * (target * 2.0 - 1.0))\n",
    "    loss = K.exp(invprobs * gamma) * loss\n",
    "    \n",
    "    return K.mean(K.sum(loss, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getfold(n):\n",
    "    val_folds = [(a + n) % 20 for a in range(0,3)]\n",
    "    train_folds = [(a + n + 3) % 20 for a in range(0,7)]\n",
    "    random.shuffle(train_folds)\n",
    "    \n",
    "    indep = np.empty([0,96,96,3])\n",
    "    dep = np.empty([0])\n",
    "    indep_val = np.empty([0,96,96,3])\n",
    "    dep_val = np.empty([0])\n",
    "    \n",
    "    for i in val_folds:\n",
    "        indep_val = np.append(indep_val, np.load(\"indep_{0}.npy\".format(i)), axis=0)\n",
    "        dep_val = np.append(dep_val, np.load(\"dep_{0}.npy\".format(i)), axis=0)\n",
    "        \n",
    "    for i in train_folds:\n",
    "        indep = np.append(indep, np.load(\"indep_{0}.npy\".format(i)), axis=0)\n",
    "        dep = np.append(dep, np.load(\"dep_{0}.npy\".format(i)), axis=0)\n",
    "    \n",
    "    return indep, dep, indep_val, dep_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Epoch 1/50\n",
      "2837/2836 [==============================] - 1820s 641ms/step - loss: 0.2921 - acc: 0.8837 - val_loss: 0.7497 - val_acc: 0.7767\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.77665, saving model to med_rn_0.h5\n",
      "Epoch 2/50\n",
      "2837/2836 [==============================] - 1810s 638ms/step - loss: 0.2488 - acc: 0.9051 - val_loss: 0.7007 - val_acc: 0.7646\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.77665\n",
      "Epoch 3/50\n",
      "2837/2836 [==============================] - 1832s 646ms/step - loss: 0.2346 - acc: 0.9129 - val_loss: 0.4953 - val_acc: 0.8062\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.77665 to 0.80623, saving model to med_rn_0.h5\n",
      "Epoch 4/50\n",
      "2837/2836 [==============================] - 1831s 646ms/step - loss: 0.2231 - acc: 0.9202 - val_loss: 0.4858 - val_acc: 0.8168\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.80623 to 0.81685, saving model to med_rn_0.h5\n",
      "Epoch 5/50\n",
      "2837/2836 [==============================] - 1807s 637ms/step - loss: 0.1944 - acc: 0.9333 - val_loss: 0.3166 - val_acc: 0.8710\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.81685 to 0.87101, saving model to med_rn_0.h5\n",
      "Epoch 6/50\n",
      "2837/2836 [==============================] - 1815s 640ms/step - loss: 0.1881 - acc: 0.9349 - val_loss: 0.3352 - val_acc: 0.8574\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.87101\n",
      "Epoch 7/50\n",
      "2837/2836 [==============================] - 1787s 630ms/step - loss: 0.1853 - acc: 0.9373 - val_loss: 0.3170 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.87101\n",
      "Epoch 8/50\n",
      "2837/2836 [==============================] - 1788s 630ms/step - loss: 0.1812 - acc: 0.9380 - val_loss: 0.3148 - val_acc: 0.8686\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.87101\n",
      "Epoch 9/50\n",
      "2837/2836 [==============================] - 1815s 640ms/step - loss: 0.1800 - acc: 0.9383 - val_loss: 0.3043 - val_acc: 0.8736\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.87101 to 0.87355, saving model to med_rn_0.h5\n",
      "Epoch 10/50\n",
      "2837/2836 [==============================] - 1777s 626ms/step - loss: 0.1821 - acc: 0.9387 - val_loss: 0.3050 - val_acc: 0.8746\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.87355 to 0.87459, saving model to med_rn_0.h5\n",
      "Epoch 11/50\n",
      "2837/2836 [==============================] - 1775s 626ms/step - loss: 0.1772 - acc: 0.9403 - val_loss: 0.3026 - val_acc: 0.8738\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.87459\n",
      "Epoch 12/50\n",
      "2837/2836 [==============================] - 1772s 625ms/step - loss: 0.1747 - acc: 0.9415 - val_loss: 0.3036 - val_acc: 0.8737\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.87459\n",
      "Epoch 13/50\n",
      "2837/2836 [==============================] - 1763s 622ms/step - loss: 0.1730 - acc: 0.9419 - val_loss: 0.2983 - val_acc: 0.8748\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.87459 to 0.87482, saving model to med_rn_0.h5\n",
      "Epoch 14/50\n",
      "2837/2836 [==============================] - 1743s 614ms/step - loss: 0.1711 - acc: 0.9423 - val_loss: 0.3122 - val_acc: 0.8703\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.87482\n",
      "Epoch 15/50\n",
      "2837/2836 [==============================] - 1738s 613ms/step - loss: 0.1693 - acc: 0.9432 - val_loss: 0.2995 - val_acc: 0.8752\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.87482 to 0.87518, saving model to med_rn_0.h5\n",
      "Epoch 16/50\n",
      "2837/2836 [==============================] - 1740s 613ms/step - loss: 0.1689 - acc: 0.9430 - val_loss: 0.2986 - val_acc: 0.8739\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.87518\n",
      "Epoch 17/50\n",
      "2837/2836 [==============================] - 1743s 614ms/step - loss: 0.1660 - acc: 0.9436 - val_loss: 0.2968 - val_acc: 0.8743\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.87518\n",
      "Epoch 18/50\n",
      "1107/2836 [==========>...................] - ETA: 16:35 - loss: 0.1742 - acc: 0.9411"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-5f168cc191d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m                           [\n\u001b[0;32m     32\u001b[0m                           \u001b[0mModelCheckpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"med_rn_{0}.h5\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'max'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m                           clr_triangular])\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    for i in range (0, 1):\n",
    "        K.clear_session()\n",
    "        indep, dep, indep_val, dep_val, res = None, None, None, None, None\n",
    "        indep, dep, indep_val, dep_val = getfold(i)\n",
    "        inputs = Input((96, 96, 3))\n",
    "        base_model = ResNeXt50(include_top=False, weights='imagenet', input_shape=(96, 96, 3), backend = keras.backend, layers = keras.layers, models = keras.models, utils = keras.utils)\n",
    "        x = base_model(inputs)\n",
    "        base_model.Trainable = False\n",
    "        out = GlobalMaxPooling2D()(x)\n",
    "        out = BatchNormalization()(out)\n",
    "        out = Dropout(0.2)(out)\n",
    "        out = Dense(256, activation='relu')(out)\n",
    "        out = Dropout(0.3)(out)\n",
    "        out = Dense(64, activation='relu')(out)\n",
    "        out = Dropout(0.3)(out)\n",
    "        out = BatchNormalization()(out)\n",
    "        out = Dense(1, activation='sigmoid')(out)\n",
    "        \n",
    "        gs1 = Model(inputs, out)\n",
    "        gs1.compile(Adam(lr=0.001), loss=\"binary_crossentropy\", metrics=['accuracy']) \n",
    "\n",
    "        with open(r\"med_rn_{0}.yaml\".format(i), \"w\") as yaml_file:\n",
    "            yaml_file.write(gs1.to_yaml())\n",
    "        clr_triangular = CyclicLR(base_lr=5e-6, max_lr=0.005, mode=\"triangular2\", step_size=1000)\n",
    "        gs1.fit_generator(generator=NPGenerator(indep=indep, dep=dep, batch_size=32, transform=preprocess_train), \n",
    "                          validation_data=NPGenerator(indep=indep_val, dep=dep_val, batch_size=32, transform=preprocess_val), \n",
    "                          steps_per_epoch=indep.shape[0]/32,\n",
    "                          validation_steps=indep_val.shape[0]/32,\n",
    "                          epochs=50, verbose=1, callbacks = \n",
    "                          [\n",
    "                          ModelCheckpoint(\"med_rn_{0}.h5\".format(i), monitor='val_acc', verbose=1, save_best_only=True, mode='max'),\n",
    "                          clr_triangular])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "90/90 [==============================] - 185s 2s/step\n",
      "0 1\n",
      "90/90 [==============================] - 186s 2s/step\n",
      "0 2\n",
      "90/90 [==============================] - 188s 2s/step\n",
      "0 3\n",
      "90/90 [==============================] - 188s 2s/step\n"
     ]
    }
   ],
   "source": [
    "res = np.load(\"res.npy\")\n",
    "data = pd.DataFrame()\n",
    "model =[]\n",
    "for i in range(0, 1):\n",
    "    with open(r\"med_rn_l{0}.yaml\".format(i), \"r\") as yaml_file:\n",
    "        K.clear_session()\n",
    "        m = model_from_yaml(yaml_file.read())\n",
    "        m.load_weights(r\"med_rn_l{0}.h5\".format(i))\n",
    "        for j in range(0,4):\n",
    "            print (i, j)\n",
    "            tg = NPGenerator(indep=res, batch_size=640, transform=preprocess_test)\n",
    "            a = m.predict_generator(tg ,verbose=1, steps=len(tg))\n",
    "            data[\"model_{0}\".format(i * 16 + j)] = pd.Series(a.reshape(len(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Epoch 1/1\n",
      "1919/1918 [==============================] - 1215s 633ms/step - loss: 0.1539 - acc: 0.9486 - val_loss: 0.3197 - val_acc: 0.8743\n",
      "\n",
      "Epoch 00001: acc improved from -inf to 0.94859, saving model to med_rn_l0.h5\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    for i in range (0, 1):\n",
    "        with open(r\"med_rn_{0}.yaml\".format(i), \"r\") as yaml_file:\n",
    "            K.clear_session()\n",
    "            indep, dep, indep_val, dep_val, res = None, None, None, None, None\n",
    "            indep, dep, indep_val, dep_val = getfold(i)\n",
    "            gs1 = model_from_yaml(yaml_file.read())\n",
    "            gs1.load_weights(\"med_rn_{0}.h5\".format(i))\n",
    "            rn = gs1.layers[1]\n",
    "            \n",
    "#            rn.Trainable = False\n",
    "#            set_trainable = False\n",
    "#            for layer in rn.layers:\n",
    "#                if layer.name == 'res5a_branch2a':\n",
    "#                    set_trainable = True\n",
    "#                if set_trainable:\n",
    "#                    layer.trainable = True\n",
    "#                else:\n",
    "#                    layer.trainable = False\n",
    "            rn.Trainable = True\n",
    "            for layer in rn.layers:\n",
    "                layer.trainable = True\n",
    "\n",
    "\n",
    "            gs1.compile(RMSprop(lr=0.00001), loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
    "            clr_triangular = CyclicLR(base_lr=1e-6, max_lr=0.00001, mode=\"triangular2\", step_size=1000)\n",
    "        \n",
    "            with open(r\"med_rn_l{0}.yaml\".format(i), \"w\") as yaml_file:\n",
    "                yaml_file.write(gs1.to_yaml())\n",
    "            gs1.fit_generator(generator=NPGenerator(indep=indep, dep=dep, batch_size=32, transform=preprocess_train), \n",
    "                          validation_data=NPGenerator(indep=indep_val, dep=dep_val, batch_size=32, transform=preprocess_val), \n",
    "                          steps_per_epoch=indep.shape[0]/32,\n",
    "                          validation_steps=indep_val.shape[0]/32,\n",
    "                          epochs=1, verbose=1, callbacks = \n",
    "                          [\n",
    "                              ModelCheckpoint(\"med_rn_l{0}.h5\".format(i), monitor='acc', verbose=1, save_best_only=True, mode='max'),\n",
    "                              clr_triangular\n",
    "                          ])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, sharex='col', figsize=(20, 10))\n",
    "ax[0].set_title('Model accuracy history')\n",
    "ax[0].plot(gs1.history.history['acc'])\n",
    "ax[0].plot(gs1.history.history['val_acc'])\n",
    "ax[0].set_ylabel('Accuracy')\n",
    "ax[0].legend(['train', 'test'], loc='right')\n",
    "ax[0].grid()\n",
    "\n",
    "ax[1].set_title('Model loss history')\n",
    "ax[1].plot(gs1.history.history['loss'])\n",
    "ax[1].plot(gs1.history.history['val_loss'])\n",
    "ax[1].set_ylabel('Loss')\n",
    "ax[1].legend(['train', 'test'], loc='right')\n",
    "ax[1].grid()\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    for i in range (0, 9):\n",
    "        with open(r\"med_dn169_lll{0}.yaml\".format(i), \"r\") as yaml_file:\n",
    "            K.clear_session()\n",
    "            indep, dep, indep_val, dep_val, res = None, None, None, None, None\n",
    "            indep, dep, indep_val, dep_val = getfold(i+10)\n",
    "            gs1 = model_from_yaml(yaml_file.read())\n",
    "            gs1.load_weights(\"med_dn169_lll{0}.h5\".format(i))\n",
    "            rn = gs1.layers[1]\n",
    "            rn.Trainable = True\n",
    "            for layer in rn.layers:\n",
    "                layer.trainable = True\n",
    "\n",
    "\n",
    "            gs1.compile(RMSprop(lr=0.001), loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
    "            clr_triangular = CyclicLR(base_lr=1e-5, max_lr=0.0001, mode=\"triangular2\", step_size=2000)\n",
    "        \n",
    "            with open(r\"med_dn169_llll{0}.yaml\".format(i), \"w\") as yaml_file:\n",
    "                yaml_file.write(gs1.to_yaml())\n",
    "            gs1.fit_generator(generator=NPGenerator(indep=indep, dep=dep, batch_size=64, transform=preprocess_train), \n",
    "                          validation_data=NPGenerator(indep=indep_val, dep=dep_val, batch_size=64, transform=preprocess_val), \n",
    "                          steps_per_epoch=indep.shape[0]/64,\n",
    "                          validation_steps=indep_val.shape[0]/64,\n",
    "                          epochs=5, verbose=1, callbacks = \n",
    "                          [\n",
    "                              ModelCheckpoint(\"med_dn169_llll{0}.h5\".format(i), monitor='acc', verbose=1, save_best_only=True, mode='max'),\n",
    "                          ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "90/90 [==============================] - 192s 2s/step\n",
      "0 1\n",
      "90/90 [==============================] - 186s 2s/step\n",
      "0 2\n",
      "90/90 [==============================] - 186s 2s/step\n",
      "0 3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-1bad26a183ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mtg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNPGenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m640\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpreprocess_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtg\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"model_{0}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict_generator\u001b[1;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[0;32m   1520\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1521\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1522\u001b[1;33m             verbose=verbose)\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mpredict_generator\u001b[1;34m(model, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[0;32m    451\u001b[0m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 453\u001b[1;33m             \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    454\u001b[0m             \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict_on_batch\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m   1272\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1273\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_predict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1274\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1275\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "res = np.load(\"res.npy\")\n",
    "data = pd.DataFrame()\n",
    "model =[]\n",
    "for i in range(0, 1):\n",
    "    with open(r\"med_rn_l{0}.yaml\".format(i), \"r\") as yaml_file:\n",
    "        K.clear_session()\n",
    "        m = model_from_yaml(yaml_file.read())\n",
    "        m.load_weights(r\"med_rn_l{0}.h5\".format(i))\n",
    "        for j in range(0,4):\n",
    "            print (i, j)\n",
    "            tg = NPGenerator(indep=res, batch_size=640, transform=preprocess_test)\n",
    "            a = m.predict_generator(tg ,verbose=1, steps=len(tg))\n",
    "            data[\"model_{0}\".format(i * 10 + j)] = pd.Series(a.reshape(len(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 57458 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = ImageDataGenerator().flow_from_directory(directory=r\"c:/users/ajaln/test/\",\n",
    "                                                    target_size=(96, 96),\n",
    "                                                    color_mode=\"rgb\", batch_size=1000,\n",
    "                                                    class_mode=\"binary\", shuffle=False)\n",
    "result = pd.DataFrame()\n",
    "result[\"id\"] = test_generator.filenames\n",
    "result[\"id\"] = result[\"id\"].str[5:45]\n",
    "result[\"label\"] = data.iloc[:,:].mean(axis=1)\n",
    "result.head()\n",
    "samples = pd.read_csv(r\"c:/users/ajaln/sample_submission.csv\", usecols=[\"id\"])\n",
    "samples = pd.merge(samples, result, on=\"id\", how=\"inner\")\n",
    "samples.head()\n",
    "samples.to_csv(r\"c:/work/dataset/medical/medical_rn.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_csv(r\"c:/work/dataset/medical/medical_dn169_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a2 = pd.read_csv(r\"C:/Work/dataset/medical/medical_rn.csv\")\n",
    "a = pd.read_csv(r\"C:/Work/dataset/medical/kl2.csv\")\n",
    "\n",
    "a[\"label\"] = (a2[\"label\"]*0.5+a[\"label\"]*0.5)\n",
    "a.loc[:, [\"id\", \"label\"]].to_csv(r\"c:/work/dataset/medical/last.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
